{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/petar/Documents/python_projects/petar-milivojevic-mlhU-machine-learning-new-mP1l/research'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/petar/Documents/python_projects/petar-milivojevic-mlhU-machine-learning-new-mP1l'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir('../')\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import json\n",
    "\n",
    "data_path = 'artifacts/data_ingestion/CodeAid Source Codes Labeling.xlsx'\n",
    "results_path = 'artifacts/train_results'\n",
    "path = 'artifacts/data_ingestion/dataset-source-codes'\n",
    "data_df = pd.read_excel(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = list(data_df['plagiarism_score'])\n",
    "input_array = []\n",
    "\n",
    "for i, row in data_df.iterrows():\n",
    "    text = ' Question: '\n",
    "\n",
    "    with open(os.path.join(path, row['coding_problem_id'], row['coding_problem_id'] + '.json'), 'r') as f:\n",
    "        file = json.load(f)\n",
    "\n",
    "    text += file['question'] + ' Candidate code: '\n",
    "\n",
    "    for dir in os.listdir(os.path.join(path, row['coding_problem_id'])):\n",
    "        if row['coding_problem_id'] + '.' in dir and 'json' not in dir:\n",
    "            file_path = os.path.join(path, row['coding_problem_id'], dir)\n",
    "\n",
    "            with open(file_path, 'r') as f:\n",
    "                script_file = f.read()\n",
    "\n",
    "            text += script_file + ' AI Code: '\n",
    "            break\n",
    "\n",
    "    for dir in os.listdir(os.path.join(path, row['coding_problem_id'])):\n",
    "        if row['llm_answer_id'] in dir:\n",
    "            file_path = os.path.join(path, row['coding_problem_id'], dir)\n",
    "    \n",
    "            with open(file_path, 'r') as f:\n",
    "                script_file = f.read()\n",
    "\n",
    "            text += script_file\n",
    "            break\n",
    "            \n",
    "    input_array.append(text)\n",
    "\n",
    "train_array, test_array, train_labels_array, test_labels_array = train_test_split(\n",
    "    input_array,\n",
    "    labels,\n",
    "    test_size=0.14,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(\n",
    "    {\n",
    "        'sample': train_array,\n",
    "        'label': train_labels_array\n",
    "    }\n",
    ")\n",
    "\n",
    "data.to_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, AdamW\n",
    "# from transformers import AutoTokenizer, AutoModelForSequenceClassification, AdamW\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score, roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "from huggingface_hub import login\n",
    "\n",
    "login(token='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')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomBERTModel(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            bert_model_name=\"bert-base-uncased\",\n",
    "            hidden_size=768,\n",
    "            intermediate_dim=256,\n",
    "            dropout_prob=0.3\n",
    "        ):\n",
    "\n",
    "        super(CustomBERTModel, self).__init__()\n",
    "        self.bert = BertForSequenceClassification.from_pretrained(bert_model_name, num_labels=1)\n",
    "        self.fc1 = nn.Linear(hidden_size, intermediate_dim)\n",
    "        self.fc2 = nn.Linear(intermediate_dim, 1)\n",
    "        self.dropout = nn.Dropout(dropout_prob)\n",
    "        self.activation = nn.ReLU()\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask, output_hidden_states=True)\n",
    "        hidden_state = outputs.hidden_states[-1][:, 0, :]  # Use [CLS]-like token representation\n",
    "        x = self.fc1(hidden_state)\n",
    "        x = self.activation(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AICodeDataset(Dataset):\n",
    "    def __init__(self, input_data, labels, tokenizer, max_len=512):\n",
    "        self.input_data = input_data\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        input_sample = self.input_data[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        inputs = self.tokenizer(\n",
    "            input_sample,\n",
    "            max_length=self.max_len,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            \"input_ids\": inputs[\"input_ids\"].squeeze(0),\n",
    "            \"attention_mask\": inputs[\"attention_mask\"].squeeze(0),\n",
    "            \"labels\": torch.tensor(label, dtype=torch.float),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metric(metric_path, range, train_matric, val_matric, train_label, val_label, fold, threshold):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(range, train_matric, label=train_label)\n",
    "    plt.plot(range, val_matric, label=val_label)\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title(f'Train/validation Loss for Fold {fold + 1}')\n",
    "    plt.legend()\n",
    "    plt.savefig(os.path.join(metric_path, f'Train_Val_{str.split(train_label)[-1]}_{fold + 1}_thr_{threshold}.png'))\n",
    "\n",
    "def plot_confusion_matrix(conf_matrix, cm_path, fold, threshold, title):\n",
    "    sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"Actual\")\n",
    "    plt.savefig(os.path.join(cm_path, f'cm_fold_{fold + 1}_thr_{threshold}.png'))\n",
    "\n",
    "def plot_roc_curve(labels, predictions, roc_curve_path, fold, threshold):\n",
    "    fpr, tpr, _ = roc_curve(labels, predictions)\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, label=\"ROC Curve\")\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.title(\"ROC Curve\")\n",
    "    plt.legend()\n",
    "    plt.savefig(os.path.join(roc_curve_path, f'roc_curve_fold_{fold + 1}_thr_{threshold}.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(model, val_loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    val_predictions = []\n",
    "    val_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(val_loader):\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            labels = batch[\"labels\"].unsqueeze(1).to(device)\n",
    "\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            preds = torch.sigmoid(outputs).cpu().detach().numpy().flatten()\n",
    "            val_predictions.extend(preds)\n",
    "            val_labels.extend(labels.cpu().numpy().flatten())\n",
    "    \n",
    "    return total_loss / len(val_loader), val_predictions, val_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_array, train_labels_array, tokenizer, num_folds, threshold, batch_size, lr, num_epochs):\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    print('Device: ', device)\n",
    "\n",
    "    dataset = AICodeDataset(train_array, train_labels_array, tokenizer)\n",
    "\n",
    "    kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "\n",
    "    for fold, (train_idx, val_idx) in tqdm(enumerate(kf.split(dataset))):\n",
    "        print(f'Fold {fold + 1}/{num_folds}')\n",
    "\n",
    "        fold_path = os.path.join(results_path, f'fold_{fold}')\n",
    "        os.makedirs(fold_path, exist_ok=True)\n",
    "\n",
    "        train_subset = Subset(dataset, train_idx)\n",
    "        val_subset = Subset(dataset, val_idx)\n",
    "\n",
    "        train_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=True)\n",
    "        val_loader = DataLoader(val_subset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "        model = CustomBERTModel().to(device)\n",
    "        optimizer = AdamW(model.parameters(), lr=lr)\n",
    "        criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "        train_losses = []\n",
    "        val_losses = []\n",
    "        train_accuracies = []\n",
    "        val_accuracies = []\n",
    "        best_val_loss = float('inf')\n",
    "        epochs_range = range(1, num_epochs + 1)\n",
    "        \n",
    "        for epoch in tqdm(range(num_epochs)):\n",
    "            total_loss = 0\n",
    "            train_preds = []\n",
    "            train_labels = []\n",
    "\n",
    "            for batch in tqdm(train_loader):\n",
    "                optimizer.zero_grad()\n",
    "                input_ids = batch[\"input_ids\"].to(device)\n",
    "                attention_mask = batch[\"attention_mask\"].to(device)\n",
    "                labels = batch[\"labels\"].unsqueeze(1).to(device)\n",
    "\n",
    "                outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "\n",
    "                preds = torch.sigmoid(outputs).squeeze().cpu().detach().numpy()\n",
    "                train_preds.extend(preds)\n",
    "                train_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "                binary_preds = [1 if pred >= threshold else 0 for pred in train_preds]\n",
    "                binary_labels = [1 if label >= threshold else 0 for label in train_labels]\n",
    "\n",
    "                accuracy = accuracy_score(binary_labels, binary_preds)\n",
    "\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                total_loss += loss.item()\n",
    "\n",
    "                sys.stdout.write(\"train_loss:%.4f - train_accuracy:%.4f\" %(loss.item(), accuracy))\n",
    "                sys.stdout.flush()\n",
    "                print()\n",
    "            \n",
    "            train_epoch_loss = total_loss / len(train_loader)\n",
    "            train_losses.append(train_epoch_loss)\n",
    "\n",
    "            val_epoch_loss, val_preds, val_labels = validation(model, val_loader, criterion, device)\n",
    "            val_losses.append(val_epoch_loss)\n",
    "            \n",
    "            model_path = os.path.join(fold_path, 'model')\n",
    "            os.makedirs(model_path, exist_ok=True)\n",
    "\n",
    "            figures_path = os.path.join(fold_path, 'figures')\n",
    "            os.makedirs(figures_path, exist_ok=True)\n",
    "\n",
    "            binary_train_preds = [1 if pred >= threshold else 0 for pred in train_preds]\n",
    "            binary_train_labels = [1 if label >= threshold else 0 for label in train_labels]\n",
    "\n",
    "            train_accuracy = accuracy_score(binary_train_labels, binary_train_preds)\n",
    "            train_accuracies.append(train_accuracy)\n",
    "\n",
    "            binary_val_preds = [1 if pred >= threshold else 0 for pred in val_preds]\n",
    "            binary_val_labels = [1 if label >= threshold else 0 for label in val_labels]\n",
    "\n",
    "            val_accuracy = accuracy_score(binary_val_labels, binary_val_preds)\n",
    "            val_accuracies.append(val_accuracy)\n",
    "\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], '\n",
    "                  f'Loss: {train_epoch_loss:.4f}, '\n",
    "                  f'Validation Loss: {val_epoch_loss:.4f}, '\n",
    "                  f'Train Accuracy: {train_accuracy:.2f}%, '\n",
    "                  f'Validation Accuracy: {val_accuracy:.2f}%')\n",
    "\n",
    "            if val_epoch_loss < best_val_loss:\n",
    "                torch.save(model.state_dict(), os.path.join(model_path, f'model_{fold}.pth'))\n",
    "                tokenizer.save_pretrained(model_path)\n",
    "\n",
    "                report = classification_report(binary_val_labels, binary_val_preds, zero_division=0, output_dict=True)\n",
    "\n",
    "                with open(os.path.join(figures_path, 'metrics_report_fold_{fold}_thr_{threshold}.json'), \"w\") as f:\n",
    "                    json.dump(report, f, indent=4)\n",
    "\n",
    "                conf_matrix = confusion_matrix(binary_val_labels, binary_val_preds)\n",
    "\n",
    "                plot_confusion_matrix(\n",
    "                    conf_matrix,\n",
    "                    figures_path,\n",
    "                    fold,\n",
    "                    threshold,\n",
    "                    'Confusion Matrix for Folt {fold} and Threshold {threshold}'\n",
    "                )\n",
    "\n",
    "                auc_score = roc_auc_score(binary_val_labels, val_preds)\n",
    "                auc_score_dict = {'auc_score': auc_score}\n",
    "\n",
    "                with open(os.path.join(figures_path, 'auc_score_fold_{fold}_thr_{threshold}.json'), \"w\") as f:\n",
    "                    json.dump(auc_score_dict, f, indent=4)\n",
    "                \n",
    "                plot_roc_curve(\n",
    "                    binary_val_labels,\n",
    "                    binary_val_preds,\n",
    "                    figures_path,\n",
    "                    fold,\n",
    "                    threshold\n",
    "                )\n",
    "        \n",
    "        plot_metric(\n",
    "            figures_path,\n",
    "            epochs_range,\n",
    "            train_losses,\n",
    "            val_losses,\n",
    "            'Train Loss',\n",
    "            'Validation Loss',\n",
    "            fold,\n",
    "            threshold\n",
    "        )\n",
    "\n",
    "        plot_metric(\n",
    "            figures_path,\n",
    "            epochs_range,\n",
    "            train_accuracies,\n",
    "            val_accuracies,\n",
    "            'Train Accuracies',\n",
    "            'Validation Accuracies',\n",
    "            fold,\n",
    "            threshold\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "num_folds = 5\n",
    "threshold = 0.5\n",
    "batch_size = 16\n",
    "lr = 2e-5\n",
    "num_epochs = 50\n",
    "\n",
    "train(train_array, train_labels_array, tokenizer, num_folds, threshold, batch_size, lr, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/tmp/ipykernel_12257/1692494090.py:7: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('artifacts/train_results/fold_0/model/model_0.pth'))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b762d9c377943bc9f222a58191cd77f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_dsataset = AICodeDataset(test_array, test_labels_array, tokenizer)\n",
    "test_loader = DataLoader(test_dsataset, batch_size=batch_size, shuffle=False)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "model = CustomBERTModel().to(device)\n",
    "model.load_state_dict(torch.load('artifacts/train_results/fold_0/model/model_0.pth'))\n",
    "\n",
    "test_loss, test_preds, test_labels = validation(model, test_loader, criterion, device)\n",
    "\n",
    "binary_test_preds = [1 if pred >= threshold else 0 for pred in test_preds]\n",
    "binary_test_labels = [1 if label >= threshold else 0 for label in test_labels]\n",
    "\n",
    "test_accuracy = accuracy_score(binary_test_labels, binary_test_preds)\n",
    "\n",
    "report = classification_report(binary_test_labels, binary_test_preds, zero_division=0, output_dict=True)\n",
    "\n",
    "conf_matrix = confusion_matrix(binary_test_labels, binary_test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': {'precision': 0.9090909090909091,\n",
       "  'recall': 1.0,\n",
       "  'f1-score': 0.9523809523809523,\n",
       "  'support': 40.0},\n",
       " '1': {'precision': 1.0,\n",
       "  'recall': 0.6923076923076923,\n",
       "  'f1-score': 0.8181818181818182,\n",
       "  'support': 13.0},\n",
       " 'accuracy': 0.9245283018867925,\n",
       " 'macro avg': {'precision': 0.9545454545454546,\n",
       "  'recall': 0.8461538461538461,\n",
       "  'f1-score': 0.8852813852813852,\n",
       "  'support': 53.0},\n",
       " 'weighted avg': {'precision': 0.9313893653516294,\n",
       "  'recall': 0.9245283018867925,\n",
       "  'f1-score': 0.9194641836151269,\n",
       "  'support': 53.0}}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
